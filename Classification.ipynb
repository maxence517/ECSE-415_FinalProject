{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Anyone against the idea of using external libraries?? If someone has a better idea, im open to suggestion\n",
    "import glob\n",
    "\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car, image number: 260518\n",
      "background, image number: 160000\n",
      "pickup_truck, image number: 50906\n",
      "articulated_truck, image number: 10346\n",
      "bus, image number: 10316\n",
      "work_van, image number: 9679\n",
      "pedestrian, image number: 6262\n",
      "single_unit_truck, image number: 5120\n",
      "bicycle, image number: 2284\n",
      "motorcycle, image number: 1982\n",
      "non-motorized_vehicle, image number: 1751\n",
      "519164\n",
      "Loading Images for category:    >>>car<<<    260518 images\n",
      "    Percentage Completed: 0%-"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6de45a862373>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;31m# for each image in the category folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[1;31m#variable update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mimgCnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgCnt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\glob.py\u001b[0m in \u001b[0;36mglob\u001b[1;34m(pathname, recursive)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mzero\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mdirectories\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msubdirectories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \"\"\"\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrecursive\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0miglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\glob.py\u001b[0m in \u001b[0;36m_iglob\u001b[1;34m(pathname, recursive, dironly)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdirname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob_in_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdironly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;31m# These 2 helper functions non-recursively glob inside a literal directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ntpath.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msep\u001b[0m  \u001b[1;31m#23780: Ensure compatible data type even if p is null.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mresult_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mp_drive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplitdrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ntpath.py\u001b[0m in \u001b[0;36msplitdrive\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[0mindex2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mindex2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnormp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcolon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# categoriesTest = np.array([ \"bicycle\", \"bus\", \"car\"])\n",
    "\n",
    "for xyz in range(3):\n",
    "    #timing\n",
    "    startGlobal = datetime.time(datetime.now())\n",
    "\n",
    "    #Initializing some useful variables\n",
    "    #We notice that runtime is minimized of operations occur on the largest categories first\n",
    "    categoriesTest  = [\"car\",\"background\",\"pickup_truck\",\"articulated_truck\",\"bus\",\"work_van\",\"pedestrian\",\n",
    "                       \"single_unit_truck\",\"bicycle\",\"motorcycle\", \"non-motorized_vehicle\"]\n",
    "    # Using reduced dataset for debuging purposes \n",
    "#     if xyz == 3:\n",
    "#         categoriesTest = np.array([\"car\", \"bus\", \"bicycle\"])#TESTTTT\n",
    "#     numCategories = categoriesTest.shape[0]#xxxxxxxx\n",
    "    numCategories = len(categoriesTest)\n",
    "#     lastIndices = np.zeros(numCategories)#XXXXXXXXX\n",
    "    RESIZE_DIM = 64\n",
    "    totalNumIm = 519164\n",
    "    totalNumFeatures = 0#TODO\n",
    "    labelsArray = np.zeros(totalNumIm, dtype=np.int)\n",
    "    featuresArray = np.zeros((totalNumIm, totalNumFeatures))\n",
    "\n",
    "#     # maxImages = 0#xxxxx\n",
    "#     sum = 0\n",
    "#     for i in range(numCategories):\n",
    "#         path = (\"MIO-TCD-Classification/train/%s/*.jpg\" % categoriesTest[i])\n",
    "#         numImages = len(glob.glob(path))\n",
    "#         print(str(categoriesTest[i]) + \", image number: \" + str(numImages))#teSTT\n",
    "#         sum = sum + numImages\n",
    "# #         lastIndices[i] = numImages-1 \n",
    "# #         if (numImages > maxImages):\n",
    "# #             maxImages = numImages#xxxxx\n",
    "#     print(sum)\n",
    "    # inputList format = [[[list of images], 'bicycle'], [[list of images], 'bus'], [[list of images], 'car'], ...]\n",
    "#     inputList = list()######\n",
    "    # inputList = np.zeros((numCategories, maxImages, 32, 32))#xxxxxxxxxx      \n",
    "    # print(inputList.shape)#xxxxxxxx\n",
    "    globalImCtr = 0\n",
    "\n",
    "    # Read input images\n",
    "    for i in range(numCategories):\n",
    "        start = datetime.time(datetime.now())\n",
    "        \n",
    "        #specifying path to images\n",
    "    #     path = (\"Dataset_test/%s/*.jpg\" % Categories_Test[i])\n",
    "        path = (\"MIO-TCD-Classification/train/%s/*.jpg\" % categoriesTest[i])\n",
    "\n",
    "        #Variable initializations\n",
    "        imgCnt = 0\n",
    "        nextPctg = 5\n",
    "        #set index of final number in this category for the iput array\n",
    "    #     numImages = lastIndices[i]#xxxxxx\n",
    "        numImages = len(glob.glob(path))#####\n",
    "        \n",
    "        #Creating the first sublist\n",
    "    #     inputList.append([[], categoriesTest[i]])#######\n",
    "        inputList.append([])#######\n",
    "\n",
    "        print(\"Loading Images for category:    >>>\" + categoriesTest[i] + \"<<<    \" + str(numImages) + \" images\")\n",
    "        print(\"    Percentage Completed: 0%-\", end='')\n",
    "        \n",
    "        # for each image in the category folder\n",
    "        for file in glob.glob(path):\n",
    "            #variable update\n",
    "            imgCnt = imgCnt + 1\n",
    "\n",
    "            #read, convert color, store\n",
    "            image = cv2.imread(file)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            #resizing IF NECESSARY\n",
    "            sy, sx = image.shape[0:2]\n",
    "            M = np.float32([[RESIZE_DIM/sx, 0, 0], [0, RESIZE_DIM/sy, 0]])\n",
    "            Input[i][0][j] = cv2.warpAffine(image, M, (RESIZE_DIM, RESIZE_DIM))\n",
    "            #end resize\n",
    "\n",
    "            ####TODO: compute features of image\n",
    "            ####TODO: store features in Array of arrays\n",
    "            \n",
    "            labelsArray[globalImCtr] = i\n",
    "            globalImCtr = globalImCtr + 1\n",
    "    #         inputList[i, imgCnt] = image#xxxxxxx\n",
    "    #         image = cv2.resize(image, (128, 128))\n",
    "            #plt.imshow(Input[i][0][j])\n",
    "            #plt.show();\n",
    "#             inputList[i].append(image)####### \n",
    "            \n",
    "            #display\n",
    "            if (int(imgCnt*100/numImages)) == nextPctg:\n",
    "                print(str(nextPctg) + \"%\", end='')\n",
    "                if nextPctg != 100 : print(\"-\", end='')\n",
    "                nextPctg = nextPctg + 5\n",
    "        #display        \n",
    "        print(\"\")\n",
    "        #timing\n",
    "        end = datetime.time(datetime.now())\n",
    "        print(\"    Duration: \" + str(datetime.combine(date.today(), end) - datetime.combine(date.today(), start)))\n",
    "\n",
    "    #Timing\n",
    "    endGlobal = datetime.time(datetime.now())\n",
    "    duration = datetime.combine(date.today(), endGlobal) - datetime.combine(date.today(), startGlobal)\n",
    "    print(\">Total duration: \" + str(duration))\n",
    "\n",
    "    \n",
    "#TODO K-fold cross-validation\n",
    "\n",
    "# print(inputList[0][0][0].shape)#xxxxxxx\n",
    "    \n",
    "# # Resize the images to (128*128) \n",
    "# # TODO Figure out the best size during optimization\n",
    "# for i in range(0, len(Input)):\n",
    "#     for j in range(0, len(Input[i][0])):\n",
    "#         sy, sx = np.array(Input[i][0])[j].shape[0:2]\n",
    "#         M = np.float32([[256/sx, 0, 0], [0, 256/sy, 0]])\n",
    "#         Input[i][0][j] = cv2.warpAffine(np.array(Input[i][0])[j], M, (256, 256))\n",
    "#         #print(\"Size: \", Input[i][0][j].shape)\n",
    "#         #plt.imshow(Input[i][0][j])\n",
    "#         #plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def HoG(input_list, cell_size, block_size, nbins):    \n",
    "    output_list = list()\n",
    "    for category in range(0, len(input_list)):\n",
    "        for index in range (0,len(input_list[category][0])):\n",
    "            \n",
    "            img = cv2.cvtColor(np.array(input_list[category][0][index]), cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            #Calculate parameters value for HOGDescriptor()\n",
    "            winSize = (img.shape[1] // cell_size[1] * cell_size[1], img.shape[0] // cell_size[0] * cell_size[0])\n",
    "            blockSize = (block_size[1] * cell_size[1], block_size[0] * cell_size[0])\n",
    "            blockStride = (cell_size[1], cell_size[0])\n",
    "            cellSize = (cell_size[1], cell_size[0])\n",
    "            \n",
    "            # create HoG Object\n",
    "            hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "            \n",
    "            n_cells = (img.shape[0] // cell_size[0], img.shape[1] // cell_size[1])\n",
    "            \n",
    "            # Compute HoG features\n",
    "            hog_feats = hog.compute(img)\n",
    "            hog_feats = hog_feats.reshape(n_cells[1]-block_size[1]+1, n_cells[0]-block_size[0]+1, block_size[0], block_size[1], nbins)\n",
    "            hog_feats = hog_feats.transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "            \n",
    "            # hog_feats now contains the gradient amplitudes for each direction,for each cell of its group for each group.\n",
    "            # Indexing is by rows then columns.\n",
    "            \n",
    "            # computation for BlockNorm\n",
    "            gradients = np.full((n_cells[0], n_cells[1], 8), 0, dtype=float)\n",
    "            cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "            \n",
    "            for off_y in range(block_size[0]):\n",
    "                for off_x in range(block_size[1]):\n",
    "                    gradients[off_y:n_cells[0] - block_size[0] + off_y + 1, off_x:n_cells[1] - block_size[1] + off_x + 1] += hog_feats[:, :, off_y, off_x, :]\n",
    "                    cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1, off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "            \n",
    "            # Average gradients\n",
    "            gradients /= cell_count\n",
    "            \n",
    "            output = gradients.reshape((1, -1))\n",
    "            output_list.append([output[0], category]) #[HoG, Category]\n",
    "            \n",
    "            \"\"\"\n",
    "            # Preview\n",
    "            plt.figure(figsize = (10,10))\n",
    "            plt.subplot(121)\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.title(\"Original Image\"), plt.xticks([]), plt.yticks([])\n",
    "            \n",
    "            bin = 0  # angle is 360 / nbins * direction\n",
    "            plt.subplot(122)\n",
    "            plt.pcolor(gradients[:, :, bin])\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            plt.title(\"HOG bin = 0\"), plt.xticks([]), plt.yticks([])\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            print()\n",
    "            \"\"\"\n",
    "    \n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute HoG features for the training images\n",
    "\n",
    "# training_output_list format: [[HoG, category], [HoG, category], [HoG, category], ...]\n",
    "training_output_list  = list()\n",
    "training_output_list = HoG(Input, (4,4), (64,64), 8) # TODO Figure out the best param during optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4025, 32768)\n",
      "(4025,)\n",
      "Predicted Label: [2 2 2 2]\n",
      "Actual Label: [0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "\n",
    "# reformat data\n",
    "data = np.array([[0 for i in range(len(training_output_list[0][0]))] for j in range(len(training_output_list))])\n",
    "target = np.array([0 for i in range(len(training_output_list))])\n",
    "\n",
    "for i in range(0, len(training_output_list)):\n",
    "    data[i][:] = training_output_list[i][0]\n",
    "    target[i] = training_output_list[i][1]\n",
    "\n",
    "print(data.shape)\n",
    "print(target.shape)\n",
    "\n",
    "clf = svm.SVC(gamma=0.001, C=100.) #\n",
    "# training, let's us all the data but the first 4 instances\n",
    "clf.fit(data[4:], target[4:])\n",
    "\n",
    "# now predict the label for the first 4 instances\n",
    "print(\"Predicted Label:\", clf.predict(data[:4]))\n",
    "print(\"Actual Label:\", target[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
